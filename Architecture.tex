\subsection{Architecture}
Figure \ref{fig:architecture} depicts SQUAAD's architecture.

\begin{figure}[h]
	\centering
	\includegraphics[width=\columnwidth]{architecture}
	\caption{The Architecture of SQUAAD}
	\label{fig:architecture}
	\vspace{-0.7cm}
\end{figure}

SQUAAD distributes the analysis over multiple ``\textbf{RecoveryUnits}''s.
A RecoveryUnit can be a cloud instance, a virtual machine (deployed on an on-premise server), or a process.
Each RecoveryUnit downloads the source code of multiple revisions, compiles the source code, and runs program analysis on source/byte code.
For complex analyses that need either a server deployment (e.g., SonarQube) or an isolated environment (e.g., test coverage in sandbox), SQUAAD provisions the RecoveryUnits on virtual machines (e.g., cloud instances).

Each RecoveryUnit contains a ``\textbf{HistoryCompiler}'' that automatically runs different build commands on the source code of a revision.
Compiling older revisions of a software system may be challenging.
The structure of modules and their build tools can change.
Some dependencies, such as older snapshot versions of libraries, might be removed from dependency repositories (e.g., MvnRepository).
A HistoryCompiler executes the compile command(s) declared in a subject system's configuration file on each revision.
It employs different versions of Java and build tools (e.g., Maven).
If there are multiple declared compile commands in the configuration file, they will be executed sequentially considering their declaration order.

SQUAAD supports incorporating new program analysis tools by providing a standard ``\textbf{AnalysisWrapper}'' that serves as an interface.
It allows workflows to be defined among these wrapped tools.
This design allows tools and analyses to be re-used in different scenarios.
Multiple program analysis tools are integrated in SQUAAD, such as SonarQube, FindBugs, PMD, ARCADE, UCC, and CheckStyle.

Each AnalysisWrapper is accompanied by a ``\textbf{PreAnalysisWrapper}'' and a ``\textbf{PostAnalysisWrapper}''.
Some analysis techniques require specific environment or data before the start of the analysis.
For example, ARC \cite{garcia2013comparative} is an architecture recovery technique that requires a shared topic model extracted from multiple revisions before recovering the architecture of each revision.
In another example, SonarQube requires deployment of its own analysis server before running the analysis.
PreAnalysisWrapper prepares the environment and data for running the analysis. 
An AnalysisWrapper is invoked if and only if its PreAnalysisWrapper executes successfully.
In addition, some analysis techniques require extra work after the analysis is done. 
For example, SonarQube does not automatically generate reports.
It provides the data through its Api.
As a result, when its execution is done, the results need to be fetched.
This is done by a PostAnalysisWraper which then stores artifacts generated by an analysis into a ``\textbf{NoSQL Datastore}''.
These artifacts can be later used for further evolutionary studies.

SQUAAD distributes the analysis using its ``\textbf{Orchestrator}''.
The Orchestrator interacts with cloud infrastructures using Vagrant\footnote{https://www.vagrantup.com} which is an open-source tool to create and configure lightweight, reproducible, and portable development environments.
Using Vagrant's interface, the orchestrator performs cloud management operations, such as launching/stopping/terminating instances and setting up required software.
The Orchestrator receives a list of revisions, chronologically sorts them, and uses a round-robin algorithm to schedule analysis of each revision.
This results in a relatively balanced distribution of revisions over different RecoveryUnits and reduces the whole mining time.

We developed ``\textbf{ReportParser}''s and ``\textbf{ReportComparator}''s to retrieve and/or calculate quality metrics from the artifacts generated by program analysis techniques.
A ReportParser receives an artifact (i.e., a report) and transforms it to a map of metric-values.
This map as well as the revision's ID will be stored in a relational database.
A ReportComparator receives two reports generated by one analysis for two revisions of a software system.
It calculates the difference between the reports (e.g., architectural change) and produces a map of metric-values.
This map and the IDs of those two revisions will be stored in the database.

``\textbf{GitAnalyzer}'' downloads a project's Git repository.
It runs a light-weight mining process to retrieve all commits' meta-data and stores them in the database.
It implements Commit-Impact Analysis and Redundancy Elimination algorithms \cite{Behnamghader2017qrs} to detect impactful commits and their relationship.
This information is later used by Orchestrator to distribute revisions over multiple RecoveryUnits over cloud.

``\textbf{GitHubAnalyzer}'' retrieves organization/project's information via GitHub Api\footnote{https://developer.github.com} and stores it in our database.
This includes but not limited to, list of projects and developers of an organization, as well as, the total number of forks of a project.

``\textbf{DataAnalyzer}'' employs the data generated by other components and runs data analytics. 
The analysis may include a combination of simple statistical calculations using SQL queries and more advanced ML algorithms such as clustering.
We use PostgreSQL\footnote{https://www.postgresql.org/} as our DBMS and scikit-learn\footnote{http://scikit-learn.org/} as our data analytics library.


``\textbf{Plotter}'' visualizes the software quality evolution.
We have implemented two types of scatter plots in the Plotter: ``commit-absolute'' and ``commit-impact''.
In both types, each data point represents a commit.
The former shows the absolute value of a metric at each data point, while the latter shows the impact of commit on software quality measured by a distance metric.
Commits incorporated by a developer have the same shape and color.
For example, Figure \ref{figure:absolute} shows the evolution of the size (i.e., ncloc) and the number of code smells in the core module of an Apache software system over eight years.
The names are changed for privacy reasons. None of two trends increases monotonically over time; however, the size experiences less variation. 
Figure \ref{figure:impact} better illustrates the impact of each developer on those two quality metrics.
The ratio of commits that increase the size to the ones that decrease it is 3.00, while this ratio for the number of code smells is 1.45.

\begin{figure} [h]
	\centering
	\includegraphics[width=\columnwidth]{LC_A.png}
	\includegraphics[width=\columnwidth]{CS_A.png}
	\caption{Evolution of size (ncloc) and the number of code smells in an Apache open source project.}
	\label{figure:absolute}
	\vspace{-0.5cm}
\end{figure}


\begin{figure} [h]
	\centering
	\includegraphics[width=\columnwidth]{LC_I.png}
	\includegraphics[width=\columnwidth]{CS_I.png}
	\caption{Impact of developers on size (ncloc) and number of code smells in an Apache open source project.}
	\label{figure:impact}
	\vspace{-0.5cm}
\end{figure}